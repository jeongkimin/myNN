{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7On-gynWqNoD",
        "outputId": "fb644a74-225c-4fe9-a37c-a53a5a9739bc"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.7.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ayxDvolqOjh"
      },
      "source": [
        "%%capture\r\n",
        "!python -m spacy download en\r\n",
        "!python -m spacy download de"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urhwG9UvqOlW",
        "outputId": "d76d9b04-8b65-408d-8bc3-956e53a2812a"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch.optim as optim\r\n",
        "import math\r\n",
        "\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "if device == 'cuda':\r\n",
        "    gpu_info = !nvidia-smi\r\n",
        "    gpu_info = '\\n'.join(gpu_info)\r\n",
        "    if gpu_info.find('failed') >= 0:\r\n",
        "        print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "        print('and then re-execute this cell.')\r\n",
        "    else:\r\n",
        "        print(gpu_info)\r\n",
        "print('device :',device)\r\n",
        "print('torch.version :',torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar  4 07:34:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "device : cuda\n",
            "torch.version : 1.7.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nnuW4LxqOo_",
        "outputId": "aa4de24e-9588-436e-898e-bf802fa456b8"
      },
      "source": [
        "import spacy\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "\r\n",
        "spacy_en = spacy.load('en') # 영어 토큰화(tokenization)\r\n",
        "spacy_de = spacy.load('de') # 독일어 토큰화(tokenization)\r\n",
        "\r\n",
        "\r\n",
        "def tokenize_de(text):\r\n",
        "    return [token.text for token in spacy_de.tokenizer(text)]\r\n",
        "\r\n",
        "# 영어(English) 문장을 토큰화 하는 함수\r\n",
        "def tokenize_en(text):\r\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "SRC = Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\r\n",
        "TRG = Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\r\n",
        "train_dataset, valid_dataset, test_dataset = Multi30k.splits(exts=(\".de\", \".en\"), fields=(SRC, TRG))\r\n",
        "\r\n",
        "\r\n",
        "SRC.build_vocab(train_dataset, min_freq=2)\r\n",
        "TRG.build_vocab(train_dataset, min_freq=2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 1.04MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 276kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 265kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc6HBgxzfJrw"
      },
      "source": [
        "\r\n",
        "class PositionalEmbedding(object):\r\n",
        "    def __init__(self, d_model, max_len=512):\r\n",
        "        pe = torch.zeros(max_len, d_model, requires_grad=False).float()\r\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\r\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\r\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\r\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\r\n",
        "        self.pe = pe.unsqueeze(0)\r\n",
        "\r\n",
        "    def get_embedding_like(self, x):\r\n",
        "        return self.pe[:, :x.size(1)].expand(x.size(0), -1, -1).to(device)\r\n",
        "\r\n",
        "\r\n",
        "class TokenEmbedding(nn.Module):\r\n",
        "    def __init__(self, n_vocab, d_model):\r\n",
        "        super().__init__()\r\n",
        "        self.emb = nn.Embedding(n_vocab, d_model)\r\n",
        "        self.d_model = d_model\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.emb(x) * math.sqrt(self.d_model)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class LayerNorm(nn.Module): \r\n",
        "\r\n",
        "    def __init__(self, features, eps=1e-6):\r\n",
        "        super(LayerNorm, self).__init__()\r\n",
        "        self.a_2 = nn.Parameter(torch.ones(features, 1))\r\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features, 1))\r\n",
        "        self.eps = eps\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        mean = x.mean(-2, keepdim=True)\r\n",
        "        std = x.std(-2, keepdim=True)\r\n",
        "\r\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\r\n",
        "\r\n",
        "\r\n",
        "class EncoderBlock(nn.Module):\r\n",
        "    def __init__(self, d_hidn, n_head, dropout_ratio):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert d_hidn % n_head == 0\r\n",
        "\r\n",
        "        self.d_hidn = d_hidn\r\n",
        "        self.d_head = d_hidn // n_head\r\n",
        "        self.n_head = n_head\r\n",
        "        \r\n",
        "        self.projs = nn.Conv1d(d_hidn, d_hidn * 3, 1)\r\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\r\n",
        "        self.layer_norm1 = LayerNorm(d_hidn)\r\n",
        "        self.feedforward = nn.Sequential(nn.Conv1d(d_hidn, d_hidn, 1),\r\n",
        "                                         nn.ReLU(),\r\n",
        "                                         nn.Conv1d(d_hidn, d_hidn, 1))\r\n",
        "        \r\n",
        "        self.layer_norm2 = LayerNorm(d_hidn)\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, mask): \r\n",
        "\r\n",
        "        mbsz, n_seq = x.size(0), x.size(2)\r\n",
        "\r\n",
        "        key, que, val = self.projs(x).chunk(3, dim=1)\r\n",
        "\r\n",
        "        key = key.view(mbsz, self.n_head, -1, n_seq) #[mbsz, n_head, d_head, n_seq']\r\n",
        "        que = que.view(mbsz, self.n_head, -1, n_seq).transpose(2, 3) #[mbsz, n_head, n_seq, d_head]\r\n",
        "        \r\n",
        "        val = val.view(mbsz, self.n_head, -1, n_seq).transpose(2, 3) #[mbsz, n_head, n_seq', d_head]\r\n",
        "\r\n",
        "\r\n",
        "        w = torch.matmul(que, key) / math.sqrt(self.d_head) # [mbsz, n_head, n_seq, n_seq']\r\n",
        "        w = w.masked_fill(mask, -np.inf)\r\n",
        "        w = torch.softmax(w, dim=3)\r\n",
        "\r\n",
        "        w = self.dropout(w)\r\n",
        "        w = torch.matmul(w, val) # [mbsz, n_head, n_seq, d_head]\r\n",
        "        w = w.transpose(2, 3) # [mbsz, n_head, d_head, n_seq]\r\n",
        "        w = w.flatten(1, 2) # [mbsz, n_head * d_head, n_seq]\r\n",
        "        \r\n",
        "        x = self.layer_norm1(x + w)\r\n",
        "        x = x + self.feedforward(x)\r\n",
        "        x = self.layer_norm2(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, n_vocab, d_hidn, num_layers, n_head, dropout_ratio):\r\n",
        "        super().__init__()\r\n",
        "        self.te = TokenEmbedding(n_vocab, d_hidn)\r\n",
        "        self.pe = PositionalEmbedding(d_hidn, 512)\r\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\r\n",
        "        self.layers = nn.ModuleList([EncoderBlock(d_hidn, n_head, dropout_ratio) for _ in range(num_layers)])\r\n",
        "        \r\n",
        "\r\n",
        "    def generate_mask(self, is_pad):\r\n",
        "\r\n",
        "        mbsz, n_seq = is_pad.size()\r\n",
        "        pad_mask = src_pad.view(mbsz, 1, n_seq)\r\n",
        "        pad_mask = pad_mask.expand(-1, n_seq, -1)\r\n",
        "        pad_mask = pad_mask.unsqueeze(1)\r\n",
        "        return pad_mask\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x, is_pad):\r\n",
        "\r\n",
        "        mbsz, n_seq = src.size()    \r\n",
        "        pad_mask = self.generate_mask(is_pad)\r\n",
        "\r\n",
        "        x = self.te(x)\r\n",
        "        x = x + self.pe.get_embedding_like(x)\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = x.transpose(1, 2).contiguous()\r\n",
        "        for layer in self.layers:\r\n",
        "            x = layer(x, pad_mask)\r\n",
        "\r\n",
        "        x = x.transpose(1, 2).contiguous()\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI6VjjRxi0R5"
      },
      "source": [
        "class DecoderBlock(nn.Module):\r\n",
        "    def __init__(self, d_hidn, n_head, dropout_ratio):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert d_hidn % n_head == 0\r\n",
        "\r\n",
        "        self.d_hidn = d_hidn\r\n",
        "        self.n_head = n_head\r\n",
        "        self.d_head = d_hidn // n_head\r\n",
        "\r\n",
        "\r\n",
        "        self.projs = nn.Conv1d(d_hidn, d_hidn * 3, 1)\r\n",
        "        self.dropout1 = nn.Dropout(dropout_ratio)\r\n",
        "        self.layer_norm1 = LayerNorm(d_hidn)\r\n",
        "        \r\n",
        "        self.enc_projs = nn.Conv1d(d_hidn, d_hidn * 2, 1)\r\n",
        "        self.dropout2 = nn.Dropout(dropout_ratio)\r\n",
        "        self.layer_norm2 = LayerNorm(d_hidn)\r\n",
        "        \r\n",
        "        self.feedforward = nn.Sequential(nn.Conv1d(d_hidn, d_hidn, 1),\r\n",
        "                                         nn.ReLU(),\r\n",
        "                                         nn.Conv1d(d_hidn, d_hidn, 1))\r\n",
        "        \r\n",
        "        self.layer_norm3 = LayerNorm(d_hidn)\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, input, input_mask, e_out, e_mask):\r\n",
        "\r\n",
        "        mbsz, n_seq = input.size(0), input.size(2)\r\n",
        "\r\n",
        "        x = input\r\n",
        "        key, que, val = self.projs(x).chunk(3, dim=1)\r\n",
        "        key = key.view(mbsz, self.n_head, -1, n_seq) #[mbsz, n_head, d_head, n_seq']\r\n",
        "        que = que.view(mbsz, self.n_head, -1, n_seq).transpose(2, 3) #[mbsz, n_head, n_seq, d_head]\r\n",
        "        val = val.view(mbsz, self.n_head, -1, n_seq).transpose(2, 3) #[mbsz, n_head, n_seq', d_head]\r\n",
        "\r\n",
        "        w = torch.matmul(que, key) / math.sqrt(self.d_head) # [mbsz, n_head, n_seq, n_seq']\r\n",
        "        w = w.masked_fill(input_mask, -np.inf)\r\n",
        "        w = torch.softmax(w, dim=3)\r\n",
        "        w = self.dropout1(w)\r\n",
        "        w = torch.matmul(w, val) # [mbsz, n_head, n_seq, d_head]\r\n",
        "        w = w.transpose(2, 3) # [mbsz, n_head, d_head, n_seq]\r\n",
        "        w = w.flatten(1, 2) # [mbsz, n_head * d_head, n_seq]\r\n",
        "        x = self.layer_norm1(x + w)\r\n",
        "\r\n",
        "\r\n",
        "        enc_n_seq = e_out.size(2)\r\n",
        "\r\n",
        "        dec_que = x.view(mbsz, self.n_head, self.d_head, n_seq).transpose(2, 3) #[mbsz, n_head, n_seq, d_head]\r\n",
        "        enc_key, enc_val = self.enc_projs(e_out).chunk(2, dim=1)\r\n",
        "        enc_key = enc_key.view(mbsz, self.n_head, self.d_head, enc_n_seq) #[mbsz, n_head, d_head, enc_n_seq]\r\n",
        "        enc_val = enc_val.view(mbsz, self.n_head, self.d_head, enc_n_seq).transpose(2, 3) #[mbsz, n_head, enc_n_seq, d_head]\r\n",
        "\r\n",
        "        w = torch.matmul(dec_que, enc_key) / math.sqrt(self.d_head) #[mbsz, n_head, n_seq, enc_n_seq]\r\n",
        "        w = w.masked_fill(e_mask, -np.inf)\r\n",
        "        w = torch.softmax(w, dim=3)\r\n",
        "        w = self.dropout2(w)\r\n",
        "        w = torch.matmul(w, enc_val) #[mbsz, n_head, n_seq, d_head]\r\n",
        "        w = w.transpose(2, 3) # [mbsz, n_head, d_head, n_seq]\r\n",
        "        w = w.flatten(1, 2) # [mbsz, n_head * d_head, n_seq]\r\n",
        "\r\n",
        "        x = self.layer_norm2(x + w)\r\n",
        "        x = x + self.feedforward(x)\r\n",
        "        x = self.layer_norm3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, n_vocab, d_hidn, num_layers, n_head, dropout_ratio):\r\n",
        "        super().__init__()\r\n",
        "        self.te = TokenEmbedding(n_vocab, d_hidn)\r\n",
        "        self.pe = PositionalEmbedding(d_hidn, 512)\r\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\r\n",
        "        self.layers = nn.ModuleList([DecoderBlock(d_hidn, n_head, dropout_ratio) for _ in range(num_layers)])\r\n",
        "\r\n",
        "        self.classifier = nn.Conv1d(d_hidn, n_vocab, 1)\r\n",
        "        \r\n",
        "\r\n",
        "    def generate_enc_mask(self, is_enc_pad, input_n_seq):\r\n",
        "        mbsz, n_seq = is_enc_pad.size()\r\n",
        "        pad_mask = src_pad.view(mbsz, 1, n_seq)\r\n",
        "        pad_mask = pad_mask.expand(-1, input_n_seq, -1)\r\n",
        "        pad_mask = pad_mask.unsqueeze(1)\r\n",
        "\r\n",
        "        return pad_mask #[mbsz, 1, input_n_seq, enc_n_seq]\r\n",
        "\r\n",
        "    \r\n",
        "    def generate_input_mask(self, is_input_pad):\r\n",
        "        mbsz, input_n_seq = is_input_pad.size()\r\n",
        "        is_input_pad = is_input_pad.to(device)\r\n",
        "        pad_mask = is_input_pad.view(mbsz, 1, input_n_seq)\r\n",
        "        pad_mask = pad_mask.expand(-1, input_n_seq, -1) #[mbsz, input_n_seq, input_n_seq]\r\n",
        "\r\n",
        "        ar_mask = torch.tril(torch.ones(input_n_seq, input_n_seq), diagonal=-1).transpose(0, 1)\r\n",
        "        ar_mask = ar_mask.view(1, input_n_seq, input_n_seq).expand(mbsz, -1, -1).to(device)\r\n",
        "\r\n",
        "        input_mask = torch.logical_or(pad_mask, ar_mask)\r\n",
        "        input_mask = input_mask.unsqueeze(1)\r\n",
        "        return input_mask\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, input, is_input_pad, enc, is_enc_pad):\r\n",
        "\r\n",
        "        mbsz, input_n_seq = input.size()    \r\n",
        "        \r\n",
        "        e_mask = self.generate_enc_mask(is_enc_pad, input_n_seq)\r\n",
        "        input_mask = self.generate_input_mask(is_input_pad)\r\n",
        "        x = self.te(input)\r\n",
        "        x = x + self.pe.get_embedding_like(x)\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = x.transpose(1, 2).contiguous()\r\n",
        "\r\n",
        "        enc = enc.transpose(1, 2).contiguous()\r\n",
        "        for layer in self.layers:\r\n",
        "            x = layer(x, input_mask, enc, e_mask)\r\n",
        "        x = self.classifier(x)\r\n",
        "        x = x.transpose(1, 2).contiguous()\r\n",
        "        \r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "    def generate(self, max_len, trg_field, enc, is_enc_pad):\r\n",
        "\r\n",
        "        assert enc.size(0) == 1\r\n",
        "\r\n",
        "        input = torch.zeros(1, max_len).long().to(device)\r\n",
        "        input[0][0] = trg_field.vocab['<sos>']\r\n",
        "        \r\n",
        "        input_pad_mask = torch.zeros_like(input).bool().to(device)\r\n",
        "\r\n",
        "        seq = []\r\n",
        "        self.eval()\r\n",
        "        with torch.no_grad():\r\n",
        "            for i in range(max_len):\r\n",
        "                x = input\r\n",
        "                out = self.forward(x, input_pad_mask, enc, is_enc_pad)\r\n",
        "                argmax = out[0][i].argmax().item()\r\n",
        "                if i != max_len - 1:\r\n",
        "                    input[0][i + 1] = argmax\r\n",
        "                \r\n",
        "            \r\n",
        "                if argmax == trg_field.vocab['<eos>']:\r\n",
        "                    break\r\n",
        "\r\n",
        "                seq.append(argmax)\r\n",
        "        self.train()\r\n",
        "\r\n",
        "        str_seq = [trg_field.vocab.itos[idx] for idx in seq]\r\n",
        "        \r\n",
        "    return \" \".join(str_seq)\r\n",
        "\r\n",
        "    \r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        \r\n",
        "        \r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1nAmZVimmgd"
      },
      "source": [
        "mbsz = 128\r\n",
        "train_iterator, test_iterator = BucketIterator.splits((train_dataset, test_dataset), batch_size=mbsz)\r\n",
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "HIDDEN_DIM = 256\r\n",
        "ENC_LAYERS = 6\r\n",
        "DEC_LAYERS = 6\r\n",
        "ENC_HEADS = 8\r\n",
        "DEC_HEADS = 8\r\n",
        "ENC_DROPOUT = 0.1\r\n",
        "DEC_DROPOUT = 0.1\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM,  d_hidn=HIDDEN_DIM, num_layers=ENC_LAYERS, n_head=ENC_HEADS, dropout_ratio=ENC_DROPOUT).to(device)\r\n",
        "dec = Decoder(OUTPUT_DIM, d_hidn=HIDDEN_DIM, num_layers=DEC_LAYERS, n_head=DEC_HEADS, dropout_ratio=DEC_DROPOUT).to(device)\r\n",
        "enc_solver = optim.Adam(enc.parameters(), lr=0.0005)\r\n",
        "dec_solver = optim.Adam(dec.parameters(), lr=0.0005)\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG.vocab.stoi['<pad>'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692TMSTLCyho",
        "outputId": "2c201b38-48b4-414e-d628-363bc74e2c19"
      },
      "source": [
        "TRG.vocab['<sos>']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "pfh5fVQuqmuq",
        "outputId": "33a00858-6250-4920-8209-0c88c4fa3f51"
      },
      "source": [
        "num_epochs = 50\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    train_loss = 0.0\r\n",
        "    for i, batch in enumerate(train_iterator):\r\n",
        "\r\n",
        "\r\n",
        "        src = batch.src.to(device)\r\n",
        "\r\n",
        "        trg = batch.trg.to(device)\r\n",
        "\r\n",
        "\r\n",
        "        dec_input = trg[:, :-1]\r\n",
        "        dec_target = trg[:,  1:]\r\n",
        "        \r\n",
        "        src_pad = (src == SRC.vocab.stoi['<pad>']).to(device)\r\n",
        "        dec_input_pad = (dec_input == TRG.vocab.stoi['<pad>']).to(device)\r\n",
        "\r\n",
        "        enc_solver.zero_grad()\r\n",
        "        dec_solver.zero_grad()\r\n",
        "\r\n",
        "        e_out = enc(src, src_pad)\r\n",
        "\r\n",
        "        \r\n",
        "        decoded = dec(dec_input, dec_input_pad, e_out, src_pad)\r\n",
        "\r\n",
        "        loss = criterion(decoded.flatten(0, 1), dec_target.flatten(0, 1))\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        enc_solver.step()\r\n",
        "        dec_solver.step()\r\n",
        "        train_loss += loss.item()\r\n",
        "        \r\n",
        "    print(train_loss / len(train_iterator))\r\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.105519136044685\n",
            "0.1056904771451383\n",
            "0.1053124478472487\n",
            "0.10749061619001338\n",
            "0.10598416895593316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3e09639d2d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e7290641753c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, is_input_pad, enc, is_enc_pad)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e7290641753c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, input_mask, e_out, e_mask)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [mbsz, n_head * d_head, n_seq]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-674a78557c90>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAqeS6VNHmzW",
        "outputId": "8db36295-cc6d-4eaa-916c-d13c24d875e3"
      },
      "source": [
        "example_idx = 5\r\n",
        "\r\n",
        "src = vars(test_dataset.examples[example_idx])['src']\r\n",
        "trg = vars(test_dataset.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(\" \".join(src))\r\n",
        "print(\" \".join(trg))\r\n",
        "\r\n",
        "enc.eval()\r\n",
        "with torch.no_grad():\r\n",
        "    src = [SRC.vocab.stoi['<sos>']] + [SRC.vocab.stoi[token.lower()] for token in src] + [SRC.vocab.stoi['<eos>']]\r\n",
        "    src = torch.LongTensor(src).unsqueeze(0).to(device)\r\n",
        "    src_pad = (src == SRC.vocab.stoi['<pad>']).to(device)\r\n",
        "    encoded = enc(src, src_pad)\r\n",
        "enc.train()\r\n",
        "\r\n",
        "encoded = enc(src, src_pad)\r\n",
        "max_len = 50\r\n",
        "dec.generate(max_len, TRG, encoded, src_pad)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ein hell gekleideter mann fotografiert eine gruppe von männern in dunklen anzügen und mit hüten , die um eine frau in einem trägerlosen kleid herum stehen .\n",
            "a man in light colored clothing photographs a group of men wearing dark suits and hats standing around a woman dressed in a strapless gown .\n",
            "a group of men in white dress and a man take a picture of a woman dressed in a dark dress and feathered wait around them .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}