{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-20\n",
    "\n",
    "def rand_gumbel(shape):\n",
    "    u = torch.rand(shape)\n",
    "    return -torch.log(-torch.log(u + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_max_sampling(logits):\n",
    "    \"\"\"\n",
    "    input = shape(*, n_class)\n",
    "    return.shape: [*, n_class], one-hot vector\n",
    "    \"\"\"\n",
    "    y = nn.functional.log_softmax(logits, dim=-1) + rand_gumbel(logits.shape)\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, y.shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(y.size())\n",
    "    return y_hard.view(y.size())\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, tau):\n",
    "    \"\"\"\n",
    "    input = shape(*, n_class)\n",
    "    return.shape: [*, n_class], gumbel_softmax vector\n",
    "    \"\"\"\n",
    "    y = logits + rand_gumbel(logits.shape)\n",
    "    return nn.functional.softmax(y / tau, dim=-1)\n",
    "\n",
    "\n",
    "def ST_gumbel_softmax_sample(logits, tau):\n",
    "    \"\"\"\n",
    "    input = shape(*, n_class)\n",
    "    return.shape: [*, n_class], one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, tau)\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    return (y_hard - y).detach() + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGITS = [math.log(0.1), math.log(0.2), math.log(0.3), math.log(0.4)]\n",
    "LOGITS = torch.FloatTensor([LOGITS])\n",
    "num_samples = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUMBEL MAX\n",
      "[0.0965 0.2026 0.3003 0.4006]\n"
     ]
    }
   ],
   "source": [
    "print('GUMBEL MAX')\n",
    "samples = gumbel_max_sampling(LOGITS.repeat(num_samples, 1))\n",
    "print(samples.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_GUMBEL_SOFTMAX, tau =  0.01\n",
      "[0.10045 0.1984  0.30675 0.3944 ]\n"
     ]
    }
   ],
   "source": [
    "tau = 0.01\n",
    "print('ST_GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = ST_gumbel_softmax_sample(LOGITS.repeat(num_samples, 1), tau)\n",
    "print(samples.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_GUMBEL_SOFTMAX, tau =  0.1\n",
      "[0.1008  0.20215 0.29855 0.3985 ]\n"
     ]
    }
   ],
   "source": [
    "tau = 0.1\n",
    "print('ST_GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = ST_gumbel_softmax_sample(LOGITS.repeat(num_samples, 1), tau)\n",
    "print(samples.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_GUMBEL_SOFTMAX, tau =  1.0\n",
      "[0.10035 0.2014  0.29985 0.3984 ]\n"
     ]
    }
   ],
   "source": [
    "tau = 1.0\n",
    "print('ST_GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = ST_gumbel_softmax_sample(LOGITS.repeat(num_samples, 1), tau)\n",
    "print(samples.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_GUMBEL_SOFTMAX, tau =  10.0\n",
      "[0.09925 0.20085 0.2967  0.4032 ]\n"
     ]
    }
   ],
   "source": [
    "tau = 10.0\n",
    "print('ST_GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = ST_gumbel_softmax_sample(LOGITS.repeat(num_samples, 1), tau)\n",
    "print(samples.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_GUMBEL_SOFTMAX, tau =  100.0\n",
      "[0.1006  0.1987  0.29975 0.40095]\n"
     ]
    }
   ],
   "source": [
    "tau = 100.0\n",
    "print('ST_GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = ST_gumbel_softmax_sample(LOGITS.repeat(num_samples, 1), tau)\n",
    "print(samples.mean(dim=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUMBEL_SOFTMAX, tau =  0.01\n",
      "[[ 0.000  1.000  0.000  0.000]\n",
      " [ 0.000  0.000  0.000  1.000]\n",
      " [ 0.000  1.000  0.000  0.000]\n",
      " [ 0.000  0.000  0.000  1.000]\n",
      " [ 1.000  0.000  0.000  0.000]]\n"
     ]
    }
   ],
   "source": [
    "tau = 0.01\n",
    "print('GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = gumbel_softmax_sample(LOGITS.repeat(5, 1), tau)\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUMBEL_SOFTMAX, tau =  0.1\n",
      "[[ 0.078  0.877  0.038  0.006]\n",
      " [ 1.000  0.000  0.000  0.000]\n",
      " [ 0.000  0.000  0.963  0.037]\n",
      " [ 0.000  0.991  0.000  0.009]\n",
      " [ 0.999  0.000  0.001  0.000]]\n"
     ]
    }
   ],
   "source": [
    "tau = 0.1\n",
    "print('GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = gumbel_softmax_sample(LOGITS.repeat(5, 1), tau)\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUMBEL_SOFTMAX, tau =  10.0\n",
      "[[ 0.204  0.244  0.289  0.264]\n",
      " [ 0.229  0.246  0.258  0.268]\n",
      " [ 0.245  0.245  0.250  0.259]\n",
      " [ 0.202  0.266  0.227  0.305]\n",
      " [ 0.212  0.221  0.283  0.284]]\n"
     ]
    }
   ],
   "source": [
    "tau = 10.0\n",
    "print('GUMBEL_SOFTMAX, tau = ', tau)\n",
    "samples = gumbel_softmax_sample(LOGITS.repeat(5, 1), tau)\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
